<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Algorithm | Han]]></title>
  <link href="http://hanjc.me/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://hanjc.me/"/>
  <updated>2014-07-11T23:54:57-07:00</updated>
  <id>http://hanjc.me/</id>
  <author>
    <name><![CDATA[Zealoct]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[简单的递归和动态规划]]></title>
    <link href="http://hanjc.me/blog/2014/04/04/recursion-and-dp/"/>
    <updated>2014-04-04T22:31:50-07:00</updated>
    <id>http://hanjc.me/blog/2014/04/04/recursion-and-dp</id>
    <content type="html"><![CDATA[<h3>题目：WordBreak</h3>

<p>首先定义如下表示</p>

<p><strong>str[n:m] </strong>为字符串 str 从下标 n 开始到下标 m-1 的字串</p>

<p>例如 str = &ldquo;abcdef&rdquo; str[4:6] = &ldquo;ef"，str[1:3] = "bc"，str[3:4] = "d&rdquo;</p>

<p><strong>str[n:] </strong>为字符串从下标 n 开始直到字符串结束的子串</p>

<p>例如 str = &ldquo;abcdef&rdquo; str[2:] = ”cdef“</p>

<p><strong>str[:m] </strong>为字符串从头开始直到下标 m-1 的子串</p>

<p>例如 str = &ldquo;abcdef&rdquo; str[:3] = ”abc“</p>

<p><strong>stat[n] </strong>表示子串 str[n:] 能不能用字典中的单词表示</p>

<!-- more -->


<p>假设字符串长度是 L，那么字符下标从 0 到 L-1，定义 stat[L] = True （因为 str[L:] 是空字符串）</p>

<p>这道题的目标是计算 stat[0]，为了计算 stat[n]，我们有如下<strong>递归方程</strong></p>

<pre><code>stat[n] = 
{ dict.contains( str[n:n+1] ) &amp;&amp; stat[n+1] } ||
{ dict.contains( str[n:n+2] ) &amp;&amp; stat[n+2] } ||
...
{ dict.contains( str[n:L] ) &amp;&amp; stat[L] }
</code></pre>

<p>其中花括号括起来的部分 <code>dict.contains( str[n:n+m] ) &amp;&amp; stat[n+m]</code> 表示：子串 str[n:] 的前 m 个字符组成的子字符串是字典中的单词，并且，子串 str[n+m:] 可以被字典中的单词组成</p>

<p>只要有任意一个 m 满足上述语句，就可以说 stat[n] 为 True！</p>

<p>对于<strong>递归思想</strong>来说，我们<strong>从等式左边到右边</strong>，不去管函数具体怎么解决子问题的，只是<strong>给出如何把问题分解为更小的子问题的方法</strong>。</p>

<p>所以一个递归方法去解这道题就是：
``` python
bool stat(n) {</p>

<pre><code>if n = L { return True }

for i = n+1..L {
    #依次计算每一个花括号，任何一个为 True 就返回 True
    if dict.contains(str[n:i]) &amp;&amp; stat(i) 
        return True
}

#所有花括号都是 False，返回 False
return False
</code></pre>

<p>}
```</p>

<p>这跟你写的那个递归方法是一样的，只不过我参数里用的并不是一个真正的字符串，而是用一个数字表示当前子字符串是从那个下标开始的。</p>

<p>递归方法的一个问题就是<strong>重复计算</strong>，比如 str=&ldquo;aaaaab&rdquo;, dict = [&ldquo;a&rdquo;, &ldquo;aa&rdquo;, &ldquo;aaa&rdquo;, &ldquo;aaaa&rdquo;, &ldquo;aaaaa&rdquo;] 这个问题，当你计算 stat(&ldquo;aaaaab&rdquo;) 和 stat(&ldquo;aaaab&rdquo;) 的时候都要去计算 stat(&ldquo;aaab&rdquo;)，字符串越长，递归调用层数越深，这个问题越明显。</p>

<p>如何解决重复计算的问题，一个直观的方法就是，每当我计算完一个 stat(n) 的值的时候，我把 stat(n) 缓存下来，下次再需要计算 stat(n) 的时候我直接返回，而不去计算。这种思想用递归写是这样的：</p>

<p>``` python
boole stat_cache[L]; #缓存 stat[n] 的结果
boole stat_calced[L]; #标识 stat[n] 是否已计算
bool stat(n) {</p>

<pre><code>if n = L { return True }

if stat_calced[n] { return stat_cache[n] }

stat_calced[n] = True

for i = n+1..L {
    #依次计算每一个花括号，任何一个为 True 就返回 True
    if dict.contains(str[n:i]) &amp;&amp; stat(i) 
        stat_cache[n] = True
        return True
}

#所有花括号都是 False，返回 False
stat_cache[n] = False
return False
</code></pre>

<p>}
```</p>

<p>我没有试过，这种方法应该已经可以解决超时的问题了，但是这种方法还是会出现多层函数调用栈，而且需要一个额外的 stat_calced 数组，怎么办嘞？</p>

<p>我们再去看看那个递归方程，发现要计算 stat[n] 的值，我们需要知道 stat[n+1]&hellip;stat[L] 的值，这次我们换个方向思考，从<strong>等式右边到左边</strong>，先把右边需要用到的都计算好，然后再计算 stat[n]，先尝试解决子问题，进而解决更大的问题，这就是<strong>动态规划的方法</strong>，在这里，递归方程被称为<strong>状态转移方程</strong>。</p>

<p>已知计算 stat[n] 需要 stat[n+1]..stat[L]，而计算 stat[n+1] 需要 stat[n+2]..stat[L]，一步步退下来，我们从 stat[L] 开始，一步步往前算。当然，递归也好，动态规划也好，都需要一个<strong>根</strong>，就像数学归纳法中的 base 一样，这一题中我们的根就是 stat[L] = True</p>

<p>所以我们的代码应该是这个样子的：</p>

<p>``` python
for n = L-1 .. 0 { #loop1</p>

<pre><code>#假设所有花括号都是 False
stat[n] = False
for i = n+1..L { #loop2
    #依次计算每一个花括号，任何一个为 True 就返回 True
    if dict.contains(str[n:i]) &amp;&amp; stat(i) 
        stat[n] = True
        break
}
</code></pre>

<p>}
```</p>

<p>注意在上述代码中，loop1 相当于递归方法中的函数调用，都是对 n 做轮询，不同的是递归是从 0 到 L-1 轮询，而这里是从 L-1 到 0 来轮询。而 loop2 和递归函数中的循环是一模一样的。</p>

<p>总结一下，递归的思想是这样的，我要算 stat[n]，那我就直接开始算 stat[n]（递归调用从stat(0)开始，直接尝试计算 stat[0] ），算到算不下去了（发现计算 stat[0] 需要 stat[1] ），那就把当前的执行压栈，然后去算 stat[1]。而动态规划的思想是这样的，我先观察，发现 stat[0] 需要 stat[1]，而 stat[1] 又需要 stat[2]，最终发现 stat[L] 不依赖任何人，直接是 True，那么这时候知道了 stat[L] 我就可以算 stat[L-1]，进而可以算 stat[L-2]，然后一步步算出 stat[0]。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kosaraju算法——关于图的后序遍历的特征]]></title>
    <link href="http://hanjc.me/blog/2014/01/04/postordering-dfs/"/>
    <updated>2014-01-04T03:27:50-08:00</updated>
    <id>http://hanjc.me/blog/2014/01/04/postordering-dfs</id>
    <content type="html"><![CDATA[<p><a href="http://en.wikipedia.org/wiki/Kosaraju%27s_algorithm">Kosaraju算法</a>是一种常见的求图的强联通分量的算法，该算法先从任意结点开始对原图G进行一次DFS后序遍历，之后依据第一次DFS的结果的反向序列（即根据reverse postordering），对原图的反向图G'进行前序的DFS。在第二次DFS中，每个联通分量即为一个强联通分量。</p>

<p>算法是很简单，不过之前并没有完全搞明白，昨天晚上仔细想了下，总算弄明白了。事实上后序遍历一个图得到的序列包含了原图重要的结构信息，正是这些结构信息保证了第二次DFS能得到正确的结果。</p>

<!-- more -->




<!--  这是错的
后续遍历图所得到的后序序列满足如下特性：

对于后序序列`a1, a2, ..., am`，
的任意连续子序列`ai, ai+1, ..., aj`（其中1<=i<=j<=m），可知

1. 结点集合`{a1, a2, ..., ai-1}`不指向`{ai, ai+1, ..., aj}`
（即不存在一条边从`{a1, a2, ..., ai-1}`中任意一个结点指向
`{ai, ai+1, ..., aj}`中的某个结点）
2. 结点集合`{ai, ai+1, ..., aj}`不指向`{aj+1, aj+2, ..., am}`
 -->


<p>先简单阐述结论，<strong>第一次后序遍历是为了保证，在第二次对反向图的前序遍历中，先访问到的强联通分量不指向任何未被访问到的强联通分量</strong>。</p>

<p>下面将简单证明一下。</p>

<p>假设一个图<strong>G</strong>，共有m个结点<code>V1, V2, ..., Vm</code>，<strong>G</strong>的一个强联通分量为<em>S</em>，包含n个结点。从任意结点开始对<strong>G</strong>进行一次后序遍历，得到后序序列<code>A1, A2, ..., Am</code>。在这个序列中，我们可以找到这样一个最短的连续子序列<code>Ai, Ai+1, ..., Aj</code>，使得<em>S</em>中所有的结点都包含在该子序列中，那么该子序列将满足如下两点：</p>

<ol>
<li>结点集合<code>{A1, A2, ..., Ai-1}</code>不指向<em>S</em>（即不存在一条边从<code>{A1, A2, ..., Ai-1}</code>中任意一个结点指向<em>S</em>中的某个结点）</li>
<li><em>S</em>不指向结点集合<code>{Aj+1, Aj+2, ..., Am}</code></li>
</ol>


<p>这两点非常容易证明，我们知道<em>S</em>是一个强联通分量，<em>S</em>作为一个整体与其他任意的结点都只有单向的边，即对于任意不属于<em>S</em>的结点<em>v</em>，不可能同时存在<em>v</em>指向<em>S</em>的边和<em>S</em>指向<em>v</em>的边（否则强联通分量就是{<em>S</em>+<em>v</em>}了）。集合<code>{A1, A2, ..., Ai-1}</code>和集合<code>{Aj+1, Aj+2, ..., Am}</code>中的所有结点都满足这一条件。</p>

<p>我们先证明第一点，对于集合<code>{A1, A2, ..., Ai-1}</code>中任意结点<em>Vk</em>（1&lt;=k&lt;=i-1），如果<em>Vk</em>指向<em>S</em>，那么当访问到<em>Vk</em>的时候必然会遍历<em>Vk</em>指向<em>S</em>的那条边（注意如果<em>Vk</em>指向<em>S</em>，那么就不可能有<em>S</em>指向<em>Vk</em>的边了），而<em>S</em>是一个强联通分量，访问其中任一结点最终都会访问到整个<em>S</em>，那么在后序序列中，<em>Vk</em>必然出现在包含<em>S</em>的子序列的后边，这与<em>Vk</em>属于<code>{A1, A2, ..., Ai-1}</code>这一条件相左，因此这种情况是不可能出现的。</p>

<p>利用相似的思想我们可以证明第二点。</p>

<p>那么这两条性质对于Kosaraju算法中的第二次DFS有什么作用的？不要忘记在Kosaraju算法中还有重要的一步，那就是第二次DFS是在原始图的逆向图（结点与原图相同，边与原图的边方向相反）上进行的！所以我们第一次DFS得到的后序序列，在反向图上就会呈现出相反的特性：</p>

<ol>
<li>S不指向结点集合<code>{A1, A2, ..., Ai-1}</code></li>
<li>结点集合<code>{Aj+1, Aj+2, ..., Am}</code>不指向<em>S</em></li>
</ol>


<p>考虑结点<em>Am</em>所在的强联通分量，假设包含该强联通分量的最短子序列为<code>Ak, Ak+1, ..., Am</code>，那么套用刚刚提到的特性1，我们有如下结论：在反向图中，<strong><em>Am</em>所在的强联通分量不指向任何其他的强联通分量</strong>。所以从<em>Am</em>开始对反向图进行一次前序遍历，所有能访问到的结点均属于同一个强联通分量。接下来就是一个递归的过程了，标记了<em>Am</em>所在的强联通分量中所有的结点之后，剩下的序列满足与原始序列同样的性质，因此只需要逆着后序序列依次对反向图进行前序遍历，就能求得所有的强联通分量。因此，<strong>在第二次DFS的过程中，每访问到一个新的强联通分量，总能保证这个强联通分量没有指向未访问的强联通分量的边</strong>。</p>

<p>突然有个想法，可惜时间不够了，先留着吧：这个算法是不是可以用来做拓扑排序？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[变种2-SUM问题——优化O(n)算法中的常数 ]]></title>
    <link href="http://hanjc.me/blog/2013/08/19/two-sum-variant/"/>
    <updated>2013-08-19T01:46:00-07:00</updated>
    <id>http://hanjc.me/blog/2013/08/19/two-sum-variant</id>
    <content type="html"><![CDATA[<p>Algorithms: Design and Analysis, Part 1 这门课的第六个编程作业的第一道题，之前的编程作业题都比较直观，而这一题需要用到一点简单的优化，相比其他的题目有意思多了。</p>

<h3>题目描述：</h3>

<p>　　输入文件每一行有一个数字（可能有重复），在这所有的数字中，任选不想等的两个数字 x 和 y ，并令 t=x+y，求问在 [-10000, 10000] 区间中存在多少这样的 t 。</p>

<h3>Solution：</h3>

<p>　　这个题目的难度在于<strong>输入数据的规模</strong>，也就是文件行数（输入数字数）n，网站给出的输入文件有 100w 行，其中不重复的数字也有 99.9w 多个，如果采用最暴力的二重循环枚举的计算方法， n2 的复杂度足以让你在等待运行结果的时间里来趟港澳台自由行了。</p>

<!-- more -->


<p>　　这个 O(n2) 的算法可以很简单的优化为一个 O(n) 的算法：</p>

<p>``` ruby 算法一
for each input x {</p>

<pre><code>for t in -10000..10000 {
    y = t - x
    if y exists in the input {
        add t to result list
    }
}
</code></pre>

<p>}
```</p>

<p>　　由于哈希查询的复杂度是 1，所以整个算法的操作复杂度是 20000*n，是一个 O(n) 的算法。试着运行一下，发现这个算法需要预计12个小时才能运行完成，同 O(n2) 的暴力算法一样都是令人难以接受的。</p>

<p>　　想要进一步缩减运行时间，则必须优化 20000*n 中的那个 20000。对输入数据进行观察、统计，发现这 100w 个输入数据中最小值只有 -99,999,887,310，而最大值则高达 99,999,662,302，如果把这 100w 个数字排一下序，那么相邻两个数字之间的平均间隔高达 199,999。</p>

<p>　　对于数列中任意一个数字 x 而言，如果存在 y，使的两者之和在区间 [-10000, 10000] 之内，那么 y 必定满足 -x-10000 &lt; y &lt; -x+10000，也就是说 y 存在于一个长度为 2w 的区间之内，通过之前对输入数据的分析我们可知，整个输入数据是松散的分布在一个长度为 200 亿的区间之内的，相邻两个数字的平均间隔为 20w ，也就是说整个 200 亿的区间内，存在有许多长度为 2w 的区间不包含任何输入的数字。所以在我们之前的算法实现中，对大多数 x 而言，内层循环的 2w 次查找都是无功而返的。</p>

<p>　　为了减少不必要的查询，我们做一次压缩，把整个 200 亿长度的区间分割为长度为 5w 的子区间，并用一个布尔值表征输入数据中有没有数字落在这一区间内。区间的分割从原点开始：&hellip;[-5w, 0), [0, 5w), [5w, 2*5w)&hellip;，其中区间 [0,5w) 的索引值为 0，[5w, 10w) 的索引值为 1。我们用 h1 来存储这个压缩结果，那么 h1[0]为真就表示输入数据中至少有一个数字存在于区间 [0, 5w) 之内。在算法1的内存循环中，查询区间长度为 2w，也就是说最多查询两个 h1 的值便可以确定不存在与 x 相对应的 y 了（但是不能确定存在，也不能确定 y 的具体值）。</p>

<p>　　修改算法一，使用 h1 过滤掉不存在y的情况：</p>

<p>``` ruby 算法二
for each input x {</p>

<pre><code>a = (-x-10000)/5w
b = (-x+10000)/5w
if h1[a] || h1[b] {
    check if y really exists
}
</code></pre>

<p>}
```</p>

<p>　　算法二可以跳过大多数 x 不必检查，对于那些需要检查的，逐一遍历每一个 y 检查是否存在。注意在检查的时候，并不总是需要检查 2w 长度的区间，如果 y 的可能区间为 49000~69000，跨越了 h1[0] 和 h1[1] 两个子区间，然而 h1[0] 为 true，h1[1] 为 false，在这种情况下我们只需要检查 49000~49999 即可。在实际的运行中，算法二可以跳过大约 70% 的输入数据，然而运行仍需比较久的时间，主要是因为我们虽然花费了极小的代价就确定了一个 x 不存在相应的 y，但在可能存在相应的 y 的时候，我们依然要花较大的精力找到 y 的具体数值，按照30%的计算量来估计的话，算法二的运行时间大约是 4 个小时。</p>

<p>　　如果进行一些取舍，把区间长度缩小，那么在不存在与 x 相对应的 y 的情况下，我们可能会稍微多花一些功夫去排除，但如果存在与之匹配的 y ，我们可以在更小的区间中进行查找，减少搜索开销。因此，合理的子区间长度应该是小于 2w 的。</p>

<p>　　考虑到输入数据的稀疏性，我们可以合理的假设一个 2w 长度的子区间内只有一个 y，我们假定新的子区间长度为 L，如果 y 不存在，我们需要进行 2w/L 次查询来排除，如果 y 存在，那么除了 2w/L 次查询以外，我们还需要额外进行 L 次查询来，由之前只有30%的 x 可能有相应的 y，我们针对每个 x 的查询次数的期望大约是 (2w/L+0.3L)，该期望在L大约等于 sqrt(2w) 时最低。取 L=150，对算法二稍作修改，然后再次运行，运行时间为 147s。这里我也尝试了 L=200，运行时间是129.18s，反而比理论值高，问题应该出在 30% 这个数据之上，之前有 30% 的 x 可能存在 y 这一数据是在 5w 的区间长度上测出来的，误差较大，在区间缩小之后应该不足 30% 的 x 需要验证 y。</p>

<p>　　以上算法还可以进一步优化，我们可以结合长区间和小区间，长区间用来快速过滤 y 不存在的情况，小区间用来快速对 y 进行定位。之前选取的 5w 实在是没有必要，这里我们只要保证大区间的查询次数少，而小区间的遍历长度小即可。在实际的实现中，我选取了大区间长度为5000，小区间长度150，程序运行时间 45.37s。</p>

<p>　　经过最终的算法和算法一的复杂度都是 O(n)，但运行时间相差非常多，主要就是优化了时间复杂度 cn 中的常数 c，虽然优化后复杂度没有变化，但是运行速度会快很多。</p>

<p>附上代码（Ruby实现）：</p>

<p>``` ruby
h = Hash.new false
h1 = Hash.new false
h1step = 5000
h2 = Hash.new false
h2step = 150
sum = Hash.new false</p>

<p>File.open(ARGV[0]).each do |xx|</p>

<pre><code>x = xx.to_i
h[x] = true
h1[x/h1step] = true
h2[x/h2step] = true
</code></pre>

<p>end</p>

<p>h.keys.each do |x|</p>

<pre><code># detect whether a possible number exists with h1

s1 = (-x-10000)/h1step
t1 = (-x+10000)/h1step
(s1..t1).each do |j|
    unless h1[j] then 
        next
    end

    a1 = b1 = 0
    if s1 == t1 then
        # -x-10000 .. -x+10000
        a1 = -x-10000
        b1 = -x+10000
    elsif j==s1 then
        # -x-10000 .. (s1+1)*h1step-1
        a1 = -x-10000
        b1 = (s1+1)*h1step-1
    elsif j==t1 then
        # t1*h1step .. -x+10000
        a1 = t1*h1step 
        b1 = -x+10000
    else
        a1 = j*h1step 
        b1 = (j+1)*h1step-1
    end
    # detect that a number exists at [a1..b1]
    # the length of [a1..b1] may varies from 1 to h1step

    # further refine the range [a1..b1] with h2
    s2 = a1/h2step
    t2 = b1/h2step
    (s2..t2).each do |i| 
        unless h2[i] then 
            next
        end

        a2 = b2 = 0
        if s2==t2 then 
            a2 = a1 
            b2 = b1
        elsif i==s2 then 
            # a1 .. (s2+1)*h2step-1
            a2 = a1
            b2 = (s2+1)*h2step-1
        elsif i==t2 then
            # t2*h2step .. b1
            a2 = t2*h2step 
            b2 = b1
        else
            # i*h2step .. (i+1)*h2step-1
            a2 = i*h2step 
            b2 = (i+1)*h2step-1
        end

        # lengh of [a2..b2] should be less than h2step
        (a2..b2).each do |y|
            if h[y] then 
                sum[x+y] = true
            end
        end
    end
end
</code></pre>

<p>end</p>

<p>puts &ldquo;Size:#{sum.size}&rdquo;
```</p>
]]></content>
  </entry>
  
</feed>
